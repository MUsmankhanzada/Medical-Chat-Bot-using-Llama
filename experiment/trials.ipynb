{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c29ea992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import ctransformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b185241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone.embeddings import PineconeEmbeddings\n",
    "from langchain_pinecone.vectorstores import PineconeVectorStore\n",
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f51d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bc5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob = \"*.pdf\",\n",
    "                             loader_cls = PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d638af",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = load_pdf(\"D:\\Medical-Chat-Bot-using-Llama\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fba52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c7e014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_huggingface_embedings():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fd48ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2624\\1412518668.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2DEC165E0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2DCD43A90>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2DD7A05E0>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2D99A9730>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2D99A9460>\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001E2D818D760>\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_huggingface_embedings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8d2f2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = embeddings.embed_query(\"Hello, world! How are you?\")\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(extracted_text):\n",
    "    text_split = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "    return text_split.split_documents(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2664178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_splitter(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e986a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4251"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# print(PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0c5e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"medical-bot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58a2633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d444e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(text_chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=text_chunks, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23ba9eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Downloaded to: ./models\\models--jlallas--Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF\\snapshots\\e05e01f6dfd1aff3c39778d049aa351b233c7439\\meta-llama-3-8b-instruct-q4_k_m.gguf\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"jlallas/Meta-Llama-3-8B-Instruct-Q4_K_M-GGUF\",\n",
    "    filename=\"meta-llama-3-8b-instruct-q4_k_m.gguf\",\n",
    "    cache_dir=\"./models\"\n",
    ")\n",
    "print(\"âœ… Downloaded to:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e39ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? False\n",
      "Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available?\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fe963ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=512,\n",
    "    n_threads=8,\n",
    "    temperature=0.3,        # Default creativity level\n",
    "    top_p=0.9,              # Nucleus sampling threshold\n",
    "    frequency_penalty=0.0,  # Reduce repeated words\n",
    "    presence_penalty=0.0,   # Penalize repeating existing tokens\n",
    "    repeat_penalty=1.1,     # Discourage excessive looping\n",
    "    n_predict=128, \n",
    "    use_mmap=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeb30cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—£ï¸ Response:  Hypertension, or high blood pressure, is a condition in which the blood pressure in the arteries is elevated above normal levels. The primary symptoms of hypertension may vary depending on the individual and the severity of the condition.\n"
     ]
    }
   ],
   "source": [
    "response = llm.create_completion(\n",
    "    prompt=\"You are a medical assistant. What are the primary symptoms of hypertension?\",\n",
    "    max_tokens=100,\n",
    "    stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "print(\"ðŸ—£ï¸ Response:\", response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ad5869b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 127.0, 'source': 'D:\\\\Medical-Chat-Bot-using-Llama\\\\data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2114\\nAllergies\\nGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 114'), Document(metadata={'page': 135.0, 'source': 'D:\\\\Medical-Chat-Bot-using-Llama\\\\data\\\\Medical_book.pdf'}, page_content='foreign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of\\nreactions is triggered by harmless, everyday substances.\\nThis is the condition known as allergy, and the offend-\\ning substance is called an allergen. Common inhaled\\nallergens include pollen, dust, and insect parts from tiny\\nhouse mites. Common food allergens include nuts, fish,\\nand milk.\\nAllergic reactions involve a special set of cells in\\nthe immune system known as mast cells. Mast cells\\nserve as guards in the tissues where the body meets the\\noutside world: the skin, the mucous membranes of the')]\n"
     ]
    }
   ],
   "source": [
    "query = \"Whate are allergies\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378e4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e75f6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "langchain_llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    n_ctx=512,\n",
    "    n_threads=8,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    repeat_penalty=1.1,\n",
    "    n_gpu_layers=0,  # Set >0 if GPU acceleration\n",
    "    use_mmap=True,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "642a3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "078ec23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f8e3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=langchain_llm,  # âœ… use the wrapped version\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": 2, \"score_threshold\": 0.4}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a skin condition that occurs when pores or hair follicles become blocked. This allows a waxy material, sebum, to collect inside the pores or follicles. Normally, sebum flows out onto the skin and hair to form a protective coating, but when it cannot get out, small swellings develop on the skin surface. Bacteria and dead skin cells can also collect that can cause inflammation and lead to acne. 224\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 24\n",
      "Acne is a skin condition that occurs when pores or hair follicles become blocked. This allows a waxy material, sebum, to collect inside the pores or follicles. Normally, sebum flows out onto the skin and hair to form a protective coating, but when it cannot get out, small swellings develop on the skin surface. Bacteria and dead skin cells can also collect that can cause inflammation and lead to acne. 224\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is not curable, although long-term control is achieved in up to 60% of patients treated with conventional therapies. Wholistic physicians or nutritionists can recommend the proper amounts of herbs such as cnidium seed (Cnidium monnieri) and honeysuckle flower (Lonicera japonica). \n",
      "GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 224\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 24\n",
      "Question: how can we cure acne \n",
      "Answer: Acne is not curable, although long-term control is achieved in up to 60% of patients treated with conventional therapies. Wholistic physicians or nutritionists can recommend the proper amounts of herbs such as cnidium seed (Cnidium monnieri) and honeysuckle flower (Lonicera japonica). \n",
      "GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your question: \")\n",
    "    result = qa.invoke({\"query\": user_input})\n",
    "    print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
